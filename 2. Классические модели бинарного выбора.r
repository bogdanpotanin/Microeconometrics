# --------
# Потанин Богдан Станиславович
# Микроэконометрика в R :)
# Урок 2. Классические модели бинарного выбора
# --------

# Отключим scientific notation
options(scipen = 999)

#---------------------------------------------------
# Часть 1. Оценивание параметров модели бинарного
#          выбора с помощью пробит регрессии
#---------------------------------------------------

# Подключим дополнительные библиотеки
library("mvtnorm")                                       # симуляции из многомерного
                                                         # нормального распределения
library("numDeriv")                                      # численное дифференцирование

# Воспроизведем процесс генерации данных,
# предполагаемый классическими моделями
# бинарного выбора с линейным индексом
# Для удобства представим, что мы симулируем процесс
# трудоустройства индивида, чтобы изучить,
# как различные характеристики могут влиять
# на вероятность занятости
# Симулируем данные
set.seed(123)                                            # для воспроизводимости
n <- 10000                                               # число наблюдений                  
X <- rmvnorm(n,                                          # симулируем n наблюдений из многомерного
                                                         # нормального распределения
             c(0, 0, 0),                                 # с нулевым вектором математических ожиданий и
             matrix(c(1, 0.2, 0.3,                       # следующей ковариационной матрице
                      0.2, 1, -0.1,
                      0.3, -0.1, 1),
                    ncol = 3,
                    byrow = FALSE))
X[, 2] <- X[, 2] > 0.5                                   # сделаем регрессор X2 бинарным
X <- cbind(1, X)                                         # добавим константу как дополнительный регрессор
mu <- 0                                                  # параметры распределения
sigma <- 7                                               # случайных ошибок
u <- rnorm(n,                                            # случайные ошибки из нормального распределения
           mu,                                           # с математическим ожиданием mu и
           sigma)                                        # стандартным отклонением sigma
gamma <- c(2, 3, 4, 5, -1, 1.5, 0)                       # оцениваемые регрессионные коэффициенты,
                                                         # включая константу
# Соберем регрессоры в датафрейм
h <- data.frame("Intercept" = X[, 1],                    # константа
                "skills" = X[, 2],                       # показатель, отражающий уровень
                                                         # развития профессиональных равыков
                "male" = X[, 3],                         # пол: мужчина = 1, женщина = 0
                "experience" = X[, 4],                   # показатель, отражающий опыт работы
                "weight" = runif(n))                     # показатель веса, симулированный из
                                                         # стандартного равномерного распределения

# Создадим линейный индекс, который определяет
# зависимость латентной переменной от различных
# независимых переменных
z_li <- gamma[1] * h$Intercept +                         # константой
        gamma[2] * h$skills +                            # навыками
        gamma[3] * h$male +                              # браком
        gamma[4] * h$experience +                        # опытом
        gamma[5] * h$experience ^ 2 +                    # квадратом опыта
        gamma[6] * h$skills* h$male +                    # взаимодействием навыков и пола
        gamma[7] * h$weight                              # но не показателем веса, поскольку
                                                         # коэффициент при нем равен нулю
z_star <- z_li  + u                                      # латентная переменная как сумма
                                                         # линейного индекса и случайной ошибки
# Чтобы оценки были достаточно точными проследим,
# чтобы дисперсии случайной ошибки и линейного
# индекса были сопоставимы
var(u)                                                   # оценка дисперсии случайной ошибки
var(z_li)                                                # оценка дисперсии линейного индекса
var(z_star)                                              # оценка дисперсии латентной переменной

# Создадим наблюдаемую зависимую переменную,
# отражающую работает индивид или нет
z <- as.numeric(z_star >= 0)                             # наблюдаемое значение переменной
z <- matrix(z, ncol = 1)                                 # как матрица с одним столбцом 
h$work <- z                                              # добавим в датафрейм переменную 
                                                         # на трудоустройство
sum(h$work  / n)                                         # доля работающих индивидов

# Примечание: рассматриваемая далее модель
# приводится исключительно в иллюстративных
# целях, поэтому предполагаемые зависимости и
# экономические интерпретации коэффициентов могут 
# не совпадать с теми, что приняты в современной
# литературе в области анализа рынка труда

#*******************************
# Пользовательский уровень
#*******************************

# Воспользуемся встроенной функцией 
# для получения ММП оценок gamma с помощью
# пробит модели, предполагающей
# стандартное нормальное распределение
# случайных ошибок
model_probit <- glm(formula = work ~ skills + male +             # указываем формулу без константы, поскольку
                              experience + I(experience ^ 2) +   # она учитывается автоматически
                              I(skills * male) +
                              weight,                                                 
               data = h,                                         # датафрейм, из которого берутся зависимая
                                                                 # и независимые переменные
               family = binomial(link = "probit"))               # тип оцениваемой бинарной регрессии: в данном
                                                                 # случае используется пробит регрессия и для ее
                                                                 # замены на логит измените "probit" на "logit"
class(model_probit)                                              # возвращаемый функцией glm() объект имеет
                                                                 # класс glm
summary(model_probit)                                            # посмотрим на полученные значения при помощи
                                                                 # функции summary(), которая на основании листа,
                                                                 # возвращаемого функцией glm(), выводит его содержимое
                                                                 # в красиво виде в консоль
gamma_est <- model_probit$coefficients                           # достанем оценки коэффициентов
print(gamma_est)                                                 # и посмотрим на них
gamma_cov_est <- vcov(model_probit)                              # достанем оценку асимптотической ковариационной матрицы
print(gamma_cov_est)                                             # оценок коэффициентов и посмотрим на нее

# Примеры интерпретации:
# 1.   Коэффициент при переменной, отражающей уровень развития
#      профессиональных навыков индивида, статистически значимо 
#      отличается от нуля на любом разумном уровне значимости. 
#      Кроме того, оценка данного коэффициента имеет положительный 
#      знак. Это свидетельствует в пользу того, что, при прочих 
#      равных, профессионализм оказывает положительное влияние на 
#      вероятность трудоустройства. Данная зависимость может быть 
#      обусловлена повышенным спросом на высококвалифицированных
#      специалистов.
# 2.   Поскольку оценка коэффициента при переменной взаимодействия
#      между полом и профессионализмом положительна и соответствующий
#      коэффициент статистически значимо отличается от нуля на любом
#      разумном уровне значимости, то, возможно, при прочих равных, 
#      вероятность трудоустройства по мере развития профессиональных 
#      навыков возрастает у мужчин в большей степени, чем у женщин. 
#      Это может быть связано с дискриминацией женщин на рынке труда.
# 3.   Оценка коэффициента при переменной, отражающей, является ли
#      индивид мужчиной, положительна и соответствующий коэффициент
#      статистически значимо отличается от нуля на любом разумном 
#      уровне значимости. Это может говорить о том, что, при прочих 
#      равных, вероятность трудоустройства у мужчин выше, чем у женщин.
# 4.   Коэффициенты при переменных, отражающих опыт работы индивида.
#      оказались статистически значимо отличны от нуля на любом разумном 
#      уровне значимости. Поскольку коэффициент при линейной части оказался 
#      положительным, а при квадратичной - отрицательным, то, возможно, при 
#      прочих равных, по мере накопления опыта работы его влияние на вероятность 
#      занятости ослабевает и, нанчиная с определенного момента, становится 
#      отрицательным. Последнее может быть вызвано, например, тем, что наиболее 
#      опытные специалисты склонны открывать собственный бизнес или утрачивают 
#      интерес к своей работе со временем (профессиональное выгорание).
# 5.   Коэффициент при переменной, отражающей вес индивида, оказался статистически
#      не значимо отличен от нуля, что не позволяет говорить о наличии статистических
#      свидетельств в пользу того, что вес влияет на вероятность занятости.

# Очень важно:
# Никогда не используйте при интерпретации сильные
# формулировки, такие как: "доказывает", "устанавливает факт",
# и т.д., поскольку методы статистического анализа предоставляют
# лишь статистические свидетельства в пользу верности того
# или иного утверждения, но никак не могут его доказать. 
# Доказательства невозможны даже в естественных науках,
# включая физику, они существуют лишь в математике и даже в ней
# могут быть поставлены под сомнение из-за недостаточно четки
# формулировок базовых понятий, включая множество и точку.
# Поэтому применяйте фразы о том, что полученные рузультаты
# "свидетельствуют в пользу того-то", "возможно говорят о том-то",
# "могут быть связаны с тем, что" и т.д.

# Важный вопрос, который следует задавать себе при получении тех 
# или иных оценок: а что именно я оценил?

# Важно: мы получаем состоятельные оценки не самих
# коэффициентов gamma, а их отношения к sigma.
# Это связано с тем, что в пробит модели предполагается 
# стандартное нормальное распределение случайной ошибки, 
# в то время как на самом деле ее дисперсия может отличаться
# от единицы, что имело место в нашем случае (см. sigma).
# Фиксация (sigma = 1) связана с тем, что в противном случае
# решения задачи максимизации функции правдоподобия будет
# иметь бесконечное число решений, из-за чего gamma
# и sigma оказываются не идентифицируемыми.
data.frame("Real" = gamma,                                       # настоящие значения коэффициентов
           "Estimates" = gamma_est,                              # полученные оценки отношений
                                                                 # настоящих коэффициентов к sigma
           "Adjusted Estimates" = gamma_est * sigma)             # скорректированные (на sigma) оценки                        
# К сожалению, как правило sigma нам неизвестна и получить
# ее состоятельную оценку не представляется возможным, 
# вследствие чего вычислить скорректированные оценки 
# невозможности

# Схожая проблема возникает и при mu не равном нулю
# В таком случае константа оказывается не идентифицируема
# и вместо нее вы оцениваете сумму константы и mu

# ЗАДАНИЯ (* - непросто, ** - сложно, *** - брутально)
# 1.1.    Сравните (на глаз) точность (отклонение от истины)   
#         полученных реализаций оценок коэффициентов при:
#         1)    выборках объемом в 100, 500 и 5000 наблюдений
#         2)    значениях sigma = 1, sigma = 5 и sigma = 20
#         3)    gamma, умноженном на 5 и 0.1
#         4)    дисперсии skills равной 2, 5 и 10, при этом
#               обратите внимание на точность оценок именно
#               при данной переменной
#         5)    при корреляции между skills, male и experience
#               равной 0.1, 0.2 и 0.9: корреляция между каждой
#               парой переменных полагается одинаковой, то есть
#               сначала 0.1, затем 0.2 и наконец 0.9
#               Подсказка: обратите внимание на ковариационную
#               матрицу в функции rmvnorm()
#         6*)   альтернативном распределении случайной ошибки, заменив
#               его с нормального на стьюдента с 5 степенями свободы
#         7*)   при математическом ожидании случайной ошибки, равном
#               mu = 0, mu = 5, mu = -5, сделав акцент на различии
#               в оценках константы: объясните, откуда возникает смещение
# 1.2.    Добавьте еще одну независимую переменную I(experience ^ 3)
#         сперва только в формулу функции glm() и проверьте, будет ли
#         коэффициент при ней статистически значимо отличаться от нуля.
#         Затем добавьте ее в процесс генерации данных с коэффициентом
#         gamma равным 0.5. Повторите проверку значимости коэффициента.
# 1.3.    По аналогии с тем, как это было сделано в данном
#         разделе:
#         1)    симулируйте процесс генерации данных,
#               описывающий, как влияют на употребление индивидом
#               алкоголя его возраст, зарплата и брак. Самостоятельно
#               подберите коэффициенты gamma таким образом, чтобы
#               доля индивидов в вашей выборке, употребляющих
#               алкоголь, составляла около 0.7. Также, подбирая gamma
#               проследите, чтобы дисперсия линейного индекса не
#               отличалась от дисперсии случайной ошибки более, чем в два
#               раза, в противном случае реализации ваших оценок могут
#               существенно отличаться от истинных значений, поскольку
#               регрессоры будут объяснять малую долю изменчивости
#               латентной переменной
#         2)    добавьте эффект взаимодействия между браком и зарплатой
#         3)    добавьте еще одну независимую дамми переменную, отражающую
#               место проживания индивида: село, город или региональный центр
#               Подсказка: рассмотрите данную бинарную переменную как три
#               бинарных переменных и не включайте одну из них во избежание
#               мультиколлинеарности

#***************************************
# Академический уровень
#***************************************

# Логарифм функции правдоподобия, максимизируемый
# при использовании пробит регрессии
ProbitLnL <- function(x, z, X)                           # функция правдоподобия
{
  x <- matrix(x, ncol = 1)                               # вектор оптимизируемых параметров, то есть
                                                         # регрессионных коэффициентов,
                                                         # переводим в матрицу с одним столбцом
  z_est <- X %*% x                                       # оценка математического ожидания 
                                                         # латентной переменной
  
  n_obs <- nrow(X)                                       # количество наблюдений
  
  L_vec <- matrix(NA, nrow = n_obs,                      # вектор столбец вкладов наблюдений
                      ncol = 1)                          # в функцию правдоподобия
  
  is_z_0 <- z == 0                                       # вектор условий z = 0
  is_z_1 <- z == 1                                       # вектор условий z = 1
  
  L_vec[is_z_1] <- pnorm(z_est[is_z_1])                  # вклад наблюдений для которых zi = 1
  L_vec[is_z_0] <- 1 - pnorm(z_est[is_z_0])              # вклад наблюдений для которых zi = 0

  lnL <- sum(log(L_vec))                                 # логарифм функции правдоподобия
  
  return(lnL)
}

# Пробит регрессия
Probit <- function(formula,                              # формула
                   data)                                 # датафрейм                
{
  d <- model.frame(formula, data)                        # извлекаем переменные согласно формуле
  z <- as.matrix(d[, 1], ncol = 1)                       # зависимая переменная как первый
                                                         # столбец в d
  X <- as.matrix(d[, -1])                                # независимые переменные как все переменные
                                                         # из data кроме зависимой
  x0_n <- ncol(X)                                        # число оцениваемых параметров
  
  X_names <- names(d)[-1]                                # имена независимых переменных
  
  result <- optim(par = rep(0, x0_n),                    # в качестве начальных точек возьмем нули
                  method = "BFGS",                       # численный метод оптимизации
                  fn = ProbitLnL,                        # максимизируемая функция правдоподобия
                  control = list(maxit = 10000,          # чтобы минимизационную задачу превратить
                                 fnscale = -1,           # в максимизационную умножаем функцию на -1
                                 reltol = 1e-10),        # установим достаточно высокую точность          
                  hessian = TRUE,                        # вернем Гессиан функции
                  X = X, z = z)                          # аргументы оптимизируемой функции 
  
  
  gamma_est <- result$par                                # оценки коэффициентов
  names(gamma_est) <- X_names                            # сопоставляем имена для оценок коэффициентов
  
  as_cov_est <- solve(-result$hessian)                   # оценка асимптотической ковариационной
  colnames(as_cov_est) <- X_names                        # матрицы полученных оценок
  rownames(as_cov_est) <- X_names                        # сопоставляем имена
  
  return_list <- list("gamma" = gamma_est,               # возвращаем оценки коэффициентов и
                      "cov" = as_cov_est,                # асимптотической ковариационной матрицы
                      "data" = data,                     # возвращаем использовавшийся датафрейм
                      "lnL" = result$value,              # возвращаем логарифм функции правдоподобия
                      "X" = X,                           # возвращаем матрицу регрессоров
                      "z" = z,                           # возвращаем зависимую переменную     
                      "formula" = formula)               # возвращаем использовавшуюся формулу                          
  
  class(return_list) <- "probit"                         # для удобства назначим класс
                                                         # возвращаемой из функции переменной
  return(return_list)                                    # возвращаем результат                               
}
# Воспользуемся созданной функцией
model <- Probit(work ~ Intercept +                       # указываем формулу с константой, поскольку
                       skills + male + experience +      # она не учитывается автоматически
                       I(experience ^ 2) +                   
                       I(skills * male) +
                       weight,
                data = h)                                    
gamma_est <- model$gamma                                 # получаем оценки коэффициентов
gamma_cov_est <- model$cov                               # получаем оценку асимптотической
                                                         # ковариационной матрицы оценок
                                                         # коэффициентов

# Метод, красиво обобщающий результаты
# для пробит регрессии
summary.probit <- function(model)                        # пишем перегрузку метода summary()
{                                                        # для объектов класса probit
  n <- length(model$z)                                   # число наблюдений
  
  cat("Probit model estimation results\n")               # заголовок
  
  cat(paste("Observations:", n, "\n"))                   # пишем число наблюдений
  cat(paste("Log-likelihood:",                           # пишем логарифм функции
            round(model$lnL, 3), "\n"))                  # правдоподобия
  
  cat("---\n")                                           # для красоты
  
  cat("Coefficients:\n")                                 # для красоты
  
  gamma_est <- model$gamma                               # достаем оценки коэффициентов
  
  as_std_est <- sqrt(diag(model$cov))                    # вычисляем оценки асимптотических
                                                         # стандартных отклонений
                                                         # оценок gamma
  
  z <- gamma_est / as_std_est                            # считаем тестовые статистики
  p_value <- 2 * pmin(pnorm(z), 1 - pnorm(z))            # рассчитываем p-value
  
  m <- length(gamma_est)                                 # число оцениваемых коэффициентов
  
  stars <- rep("", m)                                    # звездочки для красоты
  stars[p_value <= 0.001] <- "***"
  stars[(p_value > 0.001) & (p_value < 0.01)] <- "**"
  stars[(p_value > 0.01) & (p_value <= 0.05)] <- "*"
  stars[(p_value > 0.05) & (p_value <= 0.1)] <- "."
  
  df <- data.frame("Estimate" = gamma_est,               # складываем информацию в датафрейм
                   "As.Std" = as_std_est,
                   "Test.Statistic" = z,
                   "p-value" = p_value,
                   "Significance" = stars)
  is_df_num_col <- sapply(df, is.numeric)                # отмечаем numeric столбцы датафрейма и
  df[, is_df_num_col] <- round(df[, is_df_num_col], 5)   # округляем их до 5-го знака после точки
  print(df)                                              # печатаем датафрейм
  cat("---\n")                                           # для красоты
  cat(paste("Signif. codes:  0 ‘***’ 0.001 ‘**’",        # для понятности  
      "0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"))                      
}
# Воспользуемся созданной функцией для
# получения наглядного результата
summary(model)

# ЗАДАНИЯ (* - непросто, ** - сложно, *** - брутально)
# 1.1.    Измените функцию Probit() таким образом,
#         чтобы константу не нужно было указывать
#         в формуле и она учитывалась автоматически
#         как в функции glm(). Проследите, чтобы функция
#         summary() при этом работала корректно
# 1.2.    Добавьте в функцию Probit() аргумент cov_method,
#         позволяющий:
#         1)    выбирать, какая оценка асимптотической ковариационной 
#               матрицы оценок будет рассчитана: обратный Гессиан, 
#               произведение Якобианов или сэндвич
#         2*)   добавьте возможность получить оценку данной
#               асимптотической ковариационной матрицы с
#               помощью бутстрапа
# 1.3*.   В функции Probit() сделайте так, чтобы
#         константа не оценивалась, а коэффициент при
#         первом из регрессоров равнялся 1. После чего
#         сделайте sigma и mu оцениваемыми параметрами.
#         Укажите, как соотносятся оценки, полученные
#         в изначальной и репараметризированной модели.
#         Примечание: поскольку при первом из регрессоров
#                     коэффициент зафиксирован на 1, то
#                     априорно предполагается, что он
#                     значим и оказывает положительно
#                     вияние на вероятность успеха
# 1.4**.  Запрограммируйте аналитический градиент функции
#         правдоподобия, максимизируемой в рамках пробит
#         модели и подключите его к функции optim() в
#         функции Probit().
# 1.5**.  Напишите модель бинарного выбора, в которой
#         вместо нормального распределения используется
#         распределение Стьюдента с 5 степенями свободы.
#         Предварительно симулируйте процесс генерации
#         данных с соответствующим распределением
#         случайных ошибок. Обеспечьте функцию summary()
# 1.6***. Пусть t1 и t2 - независимые случайные величины, имеющие 
#         распределение Стьюдента с df1 и df2 степенями свободы
#         соответственно. Также, имеется независимая от них бернулиевская
#         случайная величина V, такая, что P(V = 1) = p. Рассмотрим
#         распределение следующей случайной величины:
#         G = V * (t5 - a) + (1 - V) * (t10 + b)
#         Напишите модель бинарного выбора, в которой используется данное
#         распределение и df1, df2, a, b и p являются оцениваемыми параметрами,
#         константа не оценивается и коэффициент при первом регрессоре
#         зафиксирован на единице. Обеспечьте функцию summary()

#---------------------------------------------------
# Часть 2. Предсказанные значения пробит модели
#---------------------------------------------------

#*******************************
# Пользовательский уровень
#*******************************

# Получим оценки (предсказанные значения) вероятностей
# занятости для каждого индивида в выборке используя
# свойство инвариантности ММП оценок: обратите внимание,
# что данная вероятность является функцией от
# оцениваемых коэффициентов
z_li_adj_est <- predict(model_probit)                         # оценки деленного на стандартное отклонение
                                                              # случайной ошибки линейного индекса при
                                                              # фиксированных значениях независимых переменных
                                                              # напомним, что в данном случае в качестве латентной 
                                                              # переменной выступает склонность к трудоустройству 
                                                              # индивида
prob_1_est <- predict(model_probit, type = "response")        # оценка вероятности занятости индивида
prob_1_est <- pnorm(z_li_adj_est)                             # может быть получена двумя способами
# Сопоставим истинные и предсказанные значения
  # склонности к трудоустройству
z_li_adj <- z_li / sigma                                      # скорректированный на sigma
plot(z_li_adj, z_li_adj_est,                                  # линейный индекс склонности к трудоустройству  
     xlab = "Real",                                              
     ylab = "Estimated",
     main = "Adjusted linear index of propensity to work")
  # вероятности трудоустройства
prob_1 <- pnorm(z_li / sigma)                                 # настоящая вероятность трудоустройства
plot(prob_1, prob_1_est, 
     xlab = "Real",
     ylab = "Estimated",
     main = "Work probability")

# Оценка вероятности занятости для конкретного индивида
Boris <- data.frame("skills" = 0.5,                           # укажем характеристики
                    "male" = 1,                               # Бориса в датафрейме
                    "experience" = 0.3,
                    "weight" = 0.8)
prob_Boris <- predict(model_probit,                           # объект возвращаемый glm()
                      newdata = Boris,                        # датафрейм, с использованием значений
                                                              # которого будут предсказаны вероятности
                      type = "response")                      # предсказываем именно вероятности

# Оценка вероятности занятости для 
# средней (репрезентативной) девушки
mean_female <- data.frame("skills" = mean(h$skills),          # укажем характеристики
                          "male" = 0,                         # Бориса в датафрейме
                          "experience" = mean(h$experience),
                          "weight" = mean(h$weight))
prob_mean_female <- predict(model_probit,                     # объект возвращаемый glm()
                            newdata = mean_female,            # датафрейм, с использованием значений
                                                              # которого будут предсказаны вероятности
                            type = "response")                # предсказываем именно вероятности

# Зачастую имеет смысл рассматривать не одного, а
# несколько средних или медианных индивидов,
# сгруппированных в зависимости от некоторых
# бинарных характеристик. Например, можно отдельно
# посмотреть вероятность занятости для репрезентативной
# девушки с высшим образованием из крупного города

# ЗАДАНИЯ (* - непросто, ** - сложно, *** - брутально)
# 2.1.    Рассчитайте вероятность трудоустройства для
#         девушки с уровнем профессионализма 0.5, опытом
#         работы 0.6 и весом 0.2
# 2.2.    Рассчитайте вероятность трудоустройства для
#         мужчины с медианными характеристиками
# 2.3*.   Рассчитайте вероятность трудоустройства для
#         девушки с медианными характеристиками не используя 
#         функцию predict()

#***************************************
# Продвинутый пользовательский уровень
#***************************************

# Оценки асимптотических стандартных отклонений
# оценок коэффициентов
prob_1_est_full <- predict(model_probit, type = "response",
                           se.fit = TRUE)                    # добавляем данный аргумент, чтобы функция
                                                             # вернула лист с оценкой асимптотических
                                                             # стандартных отклонений оценок вероятностей и
prob_1_std <- prob_1_est_full$se.fit                         # достаем их из полученной переменной

# Используя полученные оценки построим 95%
# асимптотический доверительный интервал (АДИ) для
# вероятностей успеха
conf <- 0.95                                       # указываем уровень доверия
alpha <- 1 - conf
q_L_1 <- prob_1_est -                              # считаем левую границу АДИ используя 
         qnorm(1 - alpha / 2) *                    # квантиль стандартного
                                                   # нормального распределения и          
         prob_1_std                                # корень из оценки асимптотической
                                                   # дисперсии ММП оценок вероятностей
q_R_1 <- prob_1_est +                              # считаем правую границу АДИ используя 
         qnorm(1 - alpha / 2) *                    # квантиль стандартного
                                                   # нормального распределения и          
         prob_1_std                                # корень из оценки асимптотической
                                                   # дисперсии ММП оценок вероятностей
ci <- cbind(q_L_1, q_R_1)                          # смотрим полученный АДИ
colnames(ci)[1] <- paste((alpha / 2) * 100,        # добавив имена столбцам
                         "%", sep = "")            # для красоты
colnames(ci)[2] <- paste((1 - alpha / 2) * 100, 
                         "%", sep = "")
print(head(ci))                                    # посмотрим на результат

# Проверим гипотезу H0: P(Борис работает) = 0.9
H0_prob = 0.9
prob_Boris_full <- predict(model_probit,                     
                           newdata = Boris,             
                                                    
                           type = "response",
                           se.fit = TRUE)          # вновь указываем, что хотим
                                                   # получить лист с оценками асимптотических
                                                   # стандартных отклонений оценок коэффициентов
prob_Boris_std <- prob_Boris_full$se.fit           # и получаем данную оценку
st <- (prob_Boris - H0_prob) / prob_Boris_std      # статистика теста
p_value <- 2 * min(pnorm(st), 1 - pnorm(st))       # p-value теста

# Рассмотрим предсказанные значения
# зависимой переменной
n <- length(z)                                     # число наблюдений
z_pred <- as.numeric(prob_1_est > 0.5)             # предсказываем 1, если оценка вероятности
                                                   # успеха превышает 0.5 и 0 - в противном случае
# Посмотрим количество верных предсказаний
table(z, z_pred, dnn = c("Real", "Prediction"))    # в форме таблицы
true_positive <- sum((z_pred == 1) & (z == 1))     # к-во правильно предсказанных z = 1
true_negative <- sum((z_pred == 0) & (z == 0))     # к-во правильно предсказанных z = 0
true_pred <- true_positive + true_negative         # к-во правильных предсказаний
true_pred_share <- true_pred / n                   # доля верных предсказаний
# Посмотрим количество верных предсказаний в
# соответствии с наивным прогнозом, когда 
# значение зависимой переменной предсказывается
# как наиболее часто встречающееся значение
# по выборку
true_naive_pred_share <- max(mean(z), 1 - mean(z))

# ЗАДАНИЯ (* - непросто, ** - сложно, *** - брутально)
# 2.1.    Постройте 90% процентный доверительный интервал
#         для вероятности занятости 
#         1)    для Бориса
#         2)    для девушки со средними характеристиками
#         3)    для мужчины с медианными характеристиками
#         4*)   для каждого индивида в выборке
#         5**)  для Бориса, используя бутстрап
# 2.2.    На уровне значимости 0.01 проверьте гипотезу о том,
#         что с равной вероятностью является занятым и
#         безработным:
#         1)    девушка со средними характеристиками
#         2)    мужчина с медианными характеристиками
#         3*)   по отдельности для каждого индивида в выборке и
#               посчитайте долю индивидов, для которых нулевая
#               гипотеза отвергается

#*******************************
# Академический уровень
#*******************************

# Напишем функцию для расчета
# оценок (предсказаний) вероятностей
# успеха при заданных регрессорах
ProbitPredict <- function(model,                              # переменная, возвращаемая из
                                                              # созданной ранее функции для получения
                                                              # оценок пробит модели
                          newdata = NULL,                     # датафрейм, состоящий из новых наблюдений
                                                              # по независимым переменным для model, по
                                                              # умолчанию используется исходный датафрейм
                                                              # из model
                          is_prob = TRUE)                     # если TRUE, то возвращаем оценки
                                                              # оценки вероятностей, а в противном
                                                              # случае - оценки линейного индекса,
                                                              # то есть линейного индекса,
                                                              # не скорректированные на неизвестную 
                                                              # нам дисперсию случайной ошибки
{
  gamma_est <- model$gamma                                    # рассмотрим вектор оценок как
                                                              # матрицу с одним столбцом
  if(is.null(newdata))                                        # если мы осуществляем предсказания
  {                                                           # используя изначальные наблюдения, то
    newdata <- model.frame(model$formula[-2],                 # извлекаем переменные согласно формуле из
                           model$data)                        # датафрейма, сохраненного в model
                                                              # [-2] поскольку зависимая перменная нам 
                                                              # не понадобится
  } else {
    newdata <- model.frame(model$formula[-2],                 # извлекаем переменные согласно формуле из
                           newdata)                           # нового датафрейма
  }                                                           

  X <- as.matrix(newdata)                                     # независимые переменные как матрица

  linear_index_est <- X %*% gamma_est                         # оценка линейного индекса
  
  if(!is_prob)                                                # если нужно искать оценки не
  {                                                           # вероятностей, линейного индекса,
    return(linear_index_est)                                  # то возвращаем их
  }
  
  prob_est <- pnorm(linear_index_est)                         # оценки вероятностей успеха
  
  return(prob_est)
}

# Оцениваем вероятности с помощью
# написанной функции
prob_est <- ProbitPredict(model)                              # оценки вероятностей
z_latent_est <- ProbitPredict(model = model,                  # оценки линейного индекса
                              is_prob = FALSE)  
plot(prob_1, prob_est,                                        # убедимся, что оценки
     main ="Success probability",                             # верояностей близки к
     xlab = "Real", ylba = "Estimate")                        # истинным значениям

# Оценим вероятности с помощью данной 
# функции для нового индивида
Boris_new <- Boris                                            # создаем нового Бориса и 
Boris_new$Intercept <- 1                                      # добавляем ему константу
ProbitPredict(model, newdata = Boris_new)                     # оцениваем вероятность

# ЗАДАНИЯ (* - непросто, ** - сложно, *** - брутально)
# 2.1*.   Обеспечьте возможность получения предсказанных
#         вероятностей для всех написанных вами в предыдущих
#         пунктах моделей бинарного выбора
# 2.2.    При помощи дельта метода напишите функцию, 
#         рассчитывающую оценки асимптотический стандартных
#         отклонений оценок вероятностей. Убедитесь, что ваш 
#         результат совпадает с тем, что возвращает функция 
#         predict() из предыдущего раздела при (se.fit = TRUE). 
#         Выполните данное задание для:
#         1*)    пробит модели
#         2**)   запрограмированных вами ранее 
#                моделей бинарного выбора
# 2.3.    Используя результаты предыдущего пункта напишите
#         функцию, возвращающую асимптотический доверительный 
#         интервал с заданным уровнем доверия для: 
#         1*)    пробит модели
#         2**)   запрограмированных вами ранее 
#                моделей бинарного выбора
# 2.4.    Используя результаты предыдущих пунктов напишите
#         функцию, позволяющую тестировать гипотезу о равенстве
#         вероятности определенному значению и возвращающую
#         статистику и p-value теста. Выполните задание для:
#         1*)    пробит модели
#         2**)   запрограмированных вами ранее 
#                моделей бинарного выбора
#         3***)  всех моделей, предусмотрев дополнительную возможность
#                тестирования гипотезы о равенстве вероятностей для
#                двух индивидов

#---------------------------------------------------
# Часть 3. Предельные эффекты пробит модели
#---------------------------------------------------

#*******************************
# Пользовательский уровень
#*******************************

library("mfx")                                                    # расчет предельных эффектов
library("margins")                                                # расчет предельных эффектов

# Воспользуемся функцией из пакета mfx
probit_ME <- probitmfx(formula = formula(model_probit),           # формула модели
                       data = model_probit$data,                  # датафрейм модели
                       atmean = FALSE)                            # если TRUE, то считается предельный
                                                                  # эффект для среднего индивида, а
                                                                  # иначе - средний предельный эффект
print(probit_ME)                                                  # получаем оценки предельных эффектов,
                                                                  # оценки их асимптотических стандартных
                                                                  # отклонений и p-value теста о равенстве 
                                                                  # нулю
prob_1_std
# Крупный недостаток данного пакета заключается в том,
# что функции от исходных переменных рассматриваются как
# отдельные переменные, в результате, например, предельный
# эффект для линейной и квадратичной частей опыта считаются
# по отдельности.

# Можно также использовать функцию margins, которая основана
# на функции из STATA и в ней отсутствует соответствующий
# недостаток, однако время расчетов в ней очень долгое

# Сперва придется заменить "*" на ":" для всех
# переменных взаимодействия в формуле и оценить 
# модель заново
model_probit <- glm(formula = work ~ skills + male +                
                              experience + I(experience ^ 2) +  
                              skills : male +                      # меняем "*" на ":"
                              weight,                                                 
                    data = h,               
                    family = binomial(link = "probit"))

# Предельные эффекты
probit_me <- margins(model = model_probit,                         # объект, возвращаемый glm(), в котором   
                                                                   # хранятся полученные нами ранее оценки
                     variables = NULL,                             # переменная, по которой считается
                                                                   # предельный эффект: можно указать вектор
                                                                   # переменных или поставить NULL (по умолчанию) 
                                                                   # чтобы получить предельные эффекты сразу по 
                                                                   # всем независимым переменным
                    type = "response")                             # на что строится предельный эффект:
                                                                   # вероятность или линейный индекс
# Посмотрим оценки предельных эффектов по
# каждой независимой переменной
probit_me$dydx_skills                                              # предельный эффект для переменной skills
probit_me$dydx_experience                                          # предельный эффект для переменной experience
probit_me$dydx_weight                                              # предельный эффект для переменной weight
probit_me$dydx_male                                                # предельный эффект для переменной male был
                                                                   # рассчитан не корректно, словно она непрерывная
# Корректно говорить о предельном эффекта male как
# о разнице в вероятности занятости для индивидов
# с идентичными характеристиками но различной
# половой принадлежностью
  # обратимся к мужчинам
male_frame <- model$data                                            # возьмем изначальный датафрейм и превратим
male_frame$male <- 1                                                # в нем всех индивидов в мужчин
prob_male <- predict(model_probit, newdata = male_frame)            # считаем вероятности занятости для мужчин
  # обратимся к женщинам
female_frame <- model$data                                          # возьмем изначальный датафрейм и превратим
female_frame$male <- 0                                              # в нем всех индивидов в женщин
prob_female <- predict(model_probit, newdata = female_frame)        # считаем вероятности занятости для женщин
  # оценим предельный эффект переменной male
male_ME <- prob_male - prob_female                                  # для каждого индивида                       
mean(male_ME)                                                       # средний

# Обратите внимание, что предельны эффекты
# для всех индивидов разнятся
hist(probit_me$dydx_skills)
hist(male_ME)

# По поводу средних предельных эффекто можно
# получить следующие результаты:
# factor - переменная, предельный эффект которой
#          на вероятность подлежит рассмотрению
# AME - средний предельный эффект
# SE - оценка асимптотического стандартного
#      отклонения среднего предельного эффекта
# p - p-value теста о равенстве предельного
#     эффекта нулю
# lower - нижняя граница (level * 100) процентного
#         асимптотического доверительно интервала
#         для предельного эффекта 
# upper - верхняя граница (level * 100) процентного
#         асимптотического доверительно интервала
#         для предельного эффекта 
summary(probit_me,                                                 # объект, возвращаемый функцией margins(), в котором
                                                                   # хранятся полученные нами ранее оценки
        level = 0.9)                                               # скольки процентный асимптотический доверительный 
                                                                   # интервал для предельного эффекта будет построен

# Оценим предельные эффекты для Бориса
Boris_me <- margins(model = model_probit, at = Boris)
# Вначале будут указаны характеристики Бориса, при
# фиксированных значениях которых оценивался предельный
# эффект, а далее те же значения, что и раньше, но 
# поскольку у нас всего одно наблюдение, то средний
# предельный эффект будет совпадать с обычным
summary(Boris_me)

# ЗАДАНИЯ (* - непросто, ** - сложно, *** - брутально)
# 3.1.    Рассчитайте предельные эффекты
#         на вероятность занятости Бориса
#         1)    каждой непрерывной переменной
#         2*)   переменной male
# 3.2.    Постройте 99% асимптотический доверительный
#         интервал для предельного эффекта опыта на
#         вероятность занятости
# 3.3.    На уровне значимости 0.01 проверьте гипотезу
#         о равенстве нулю предельного эффекта по отдельности
#         для каждой независимой переменной
# 3.4.    Для каждой независимой перемнной рассчитайте
#         средний предельный эффект самостоятельно,
#         используя функцию mean()
# 3.5*.   Используя help(margins) разберитесь, как можно
#         получить оценки асимптотических дисперсий оценок
#         предельных эффектов опыта на вероятность занятости
#         в отношении каждого из индивидов.
#         Примечание: расчеты могут оказаться очень долгими,
#                     вплоть до нескольких десятков минут,
#                     поэтому вместо всей выборки удобней
#                     в учебных целях взять лишь ее часть
# 3.6**.  Используя результаты предыдущего пункта рассчитайте
#         долю предельных эффектов опыта на вероятность занятости,
#         которые статистически значимо отличаются от нуля

#*******************************
# Академический уровень
#*******************************

# Предельные эффекты нетрудно рассчитать вручную, 
# например, для опыта работы получаем
exp_ME <- (gamma_est["experience"] +                                # эта часть предельного эффекта зависит от того,
           2 * gamma_est["I(experience^2)"] * h$experience) *       # в какой форме регрессор входит в линейный индекс
          dnorm(z_li_adj_est)                                       # эта част предельного эффекта в пробит модели
                                                                    # остается неизменной для всех переменных
mean(exp_ME)                                                        # средний предельный эффект

# Кроме того, любой предельный эффект нетрудно рассчитать
# с помощью численного дифференцирования, что очень часто
# бывает удобно использовать в очень сложных моделях,
# где аналитический расчет производной является 
# затруднительным:
probitME <- function(model,                                         # объект возвращаемый glm()
                     variable,                                      # по какой переменной считается
                                                                    # предельный эффект
                     newdata = NULL)                                # если NULL, то считаем по исходной
                                                                    # выборке, а иначе по newdata датафрейму
{                                                              
  if(is.null(newdata))                                              # если не был подана новый датафрейм,
  {                                                                 # то считаем предельные вероятности
    newdata <- model$data                                           # по исходному
  }
  
  f0 <- predict(model,                                              # предсказанные вероятности при исходном
                                                                    # значении переменной
                newdata = newdata, 
                type = "response")
  
  my_var <- newdata[, variable]                                     # достаем переменную, по которой
                                                                    # смотрится предельный эффект
  delta <- sqrt(.Machine$double.eps) * my_var                       # выбираем приращение
  newdata[, variable] <- my_var + delta                             # добавляем приращение к переменной
                                                                    # внутри датафрейма
  f1 <- predict(model,                                              # рассчитываем вероятность успеха
                newdata = newdata,                                  # с учетом приращения в отношении
                type = "response")                                  # переменной
  
  value <- (f1 - f0) / delta                                        # считаем предельный эффект через
                                                                    # численную производнуб методом
                                                                    # forward difference
  return(value)                                               
}
# Воспользуемся функцией
skills_ME <- probitME(model = model_probit,                         # получаем оценки предельных эффектов 
                       variable = "skills")                         # способностей индивида
mean(skills_ME)                                                     # оценка среднего предельного эффекта
probitME(model = model_probit,                                      # предельный эффект способностей на
         variable = "skills",                                       # вероятность занятости Бориса
         newdata = Boris)

# ЗАДАНИЯ (* - непросто, ** - сложно, *** - брутально)
# 3.1.    Сделайте так, чтобы функция probit_ME позволяла:
#         1*)   Оценивать предельные эффекты для бинарных
#               переменных, то есть принимающих значения
#               0 или 1 как в случае с переменной male
#         2**)  Оценива предельные эффекты для дамми
#               переменных
#         3)    Использовать central difference метод
#               численного дифференцирования
# 3.2.    Для каждой из реализованных вами ранее моделей
#         бинарного выбора обеспечьте функцию, которая
#         позволяет, по аналогии с margins():
#         1*)   оценивать предельные эффекты
#         2**)  строить доверительные интервалы для
#               предельных эффектов
#         3**)  тестировать гипотезы о равенстве предельных
#               эффектов определенным значениям

#---------------------------------------------------
# Часть 4. Логистическая регрессия и 
#          отношение шансов
#---------------------------------------------------

#*******************************
# Пользовательский уровень
#*******************************

# Примечание: в данном разделе будем предполагать, что
# случайные ошибки имеют логистическое распределение,
# а не нормальное. Чтобы данное предположение
# было справедливым необходимо в первом разделе
# сгенерировать случайную ошибку из соответствующего
# распределения. В целях экономии пространства мы не будем
# этого делать, однако при самостоятельном разборе материала
# настоятельно рекомендуется проделать данный шаг.
# Также, рекомендуется изменить коэффициент gamma при weight
# на значение, отличное от нуля

# Оценим логистическую регрессию
model_logit <- glm(formula = work ~ skills + male +            
                             experience + I(experience ^ 2) +
                             I(skills * male) +
                             weight,                                                 
                             data = h,                                         

                   family = binomial(link = "logit"))                # заменили probit на logit             
gamma_est <- model_logit$coefficients                                # достанем оценки коэффициентов

# Отношение шансов - (вероятность успеха) / (вероятность неудачи)

# Оценим, во сколько раз изменится отношение 
# шансов при изменении веса индивида на единицу
OR_weight_est <- exp(gamma_est["weight"])
# Убедимся, что данное изменение не зависит от
# характеристик индивидов на примере Бориса
Boris_after_meal <- Boris                                            # создадим датафрейм, содержащий
                                                                     # характеристики Бориса после обеда,
Boris_after_meal$weight <- Boris$weight + 1                          # отличающиеся от исходных наличием
                                                                     # дополнительной единицы веса
Boris_prob <- predict(model_logit, type = "response",                # оцениваем вероятность занятости Бориса
                      newdata = Boris)                               # до обеда
Boris_afer_meal_prob <- predict(model_logit, type = "response",      # оцениваем вероятность занятости Бориса
                                newdata = Boris_after_meal)          # после обеда
OR_after_meal <- Boris_afer_meal_prob / (1 - Boris_afer_meal_prob)   # оценка отношения шансов после обеда
OR_before_meal <- Boris_prob / (1 - Boris_prob)                      # оценка отношения шансов до обеда
OR_after_meal / OR_before_meal                                       # оцениваем во сколько раз изменилось отношение,
                                                                     # шансов и видим, что полученные результат 
                                                                     # совпадает с ранее полученным значением
# Однако, такой подход является корректным лишь
# для переменных, входящих линейно, а для других
# переменных формула для изменения отношений
# шансов может выглядеть несколько сложней. Например,
# для переменной experience мы бы получили:
OR_experience_est <- exp(gamma_est["experience"] +
                         gamma_est["I(experience^2)"] +
                         2 * gamma_est["I(experience^2)"] * 
                         Boris$experience)
# То есть для разных индивидов оценка изменения
# отношений шансов может разниться в зависимости
# от их характеристик если отношение шансов
# рассматривается относительно переменной, 
# входящей не линейно

# ЗАДАНИЯ (* - непросто, ** - сложно, *** - брутально)
# 4.1.    Убедитесь, что результат для переменной experience был
#         получн корректно, построив пример с Борисом аналогичный
#         тому, что рассматривался для переменной weight
# 4.2.    Оцените, во сколько раз изменится отношение шансов
#         вероятности занятости при изменении
#         1)    переменной skills на единицу для женщин
#         2)    переменной skills на единицу для мужчин
#         3*)   переменной experience на единицу, если
#               в уравнение входит experience ^ 3
#         4*)   переменной skills на 0.3 для женщин
#         5*)   переменной skills на 0.3 для мужчин
# 4.3.    Сравните оценки, полученные с помощью логит
#         и пробит моделей. Рассмотрите оценки:
#         1)    коэффициентов gamma
#         2)    вероятностей
#         3)    линейного индекса
#         4)    предельных эффектов
#         5*)   изменений отношений шансов

#*******************************
# Академический уровень
#*******************************

# При помощи дельта метода построим 90% асимптотический
# доверительный интервал для изменения отношения шансов
# вследствие изменения переменной experience на единицу
# для Бориса
# Примечание: при этом часто рассматривают доверительные
#             интервалы для самих отношений шансов, что
#             остается в качестве упражнения

# Сперва оценим асимптотическую дисперсию
OR_experience_est_grad <- c(OR_experience_est,                       # производная по коэффициенту при experience
                            OR_experience_est *                      # производная по коэффициенту при experience ^ 2      
                            (1 + 2 * Boris$experience))              # по остальным коэффициентам частная производная
                                                                     # изменения отношений шансов равняется нулю,
                                                                     # вследствие чего не записывается в градиент
                                                                     # для удобства
OR_experience_est_grad <- matrix(OR_experience_est_grad, ncol = 1)   # преобразуем градиента в матрицу с одним столбцом
gamma_cov_est <- vcov(model_logit)                                   # оценка асимптотической ковариационной матрицы
                                                                     # оценок gamma коэффициентов
nonzero <- c("experience", "I(experience^2)")                        # независимые переменные, по которым
                                                                     # градиент не равнялся нулю
gamma_cov_est <- gamma_cov_est[nonzero, nonzero]                     # рассмотрим лишь ковариационную матрицу
                                                                     # оценок experience и experience ^ 2
OR_experience_est_cov <- t(OR_experience_est_grad) %*%
                         gamma_cov_est %*%
                         OR_experience_est_grad

# Теперь оценим границы доверительного интервала
conf <- 0.9                                                          # уровень доверия          
alpha <- 1 - conf
q_L <- OR_experience_est -                                           # оцениваем левую границу                                               
       qnorm(1 - alpha / 2) *                                             
          
       sqrt(OR_experience_est_cov)                                                         

q_R <- OR_experience_est +                                           # оцениваем правую границу             
       qnorm(1 - alpha / 2) *
        
       sqrt(OR_experience_est_cov) 

ci <- cbind(q_L, q_R)                                                # объединяем результат          
colnames(ci) <- c(paste((alpha / 2) * 100,                           # добавляем имена
                         "%", sep = ""),            
                  paste((1 - alpha / 2) * 100, 
                         "%", sep = ""))
print(ci)                                                            # посмотрим на результат

# Теперь построим 90% бутстрапированный доверительный интервал
boot_iter <- 100                                                     # число бутстрап итераций
OR_boot <- rep(NA, boot_iter)                                        # переменная, в которую будем сохранять
                                                                     # оценки изменений в отношениях
                                                                     # шансов
for(i in 1:boot_iter)                       
{
  h_rows_ind <- sample(1:n, n, TRUE)                                 # случайным образом отбираем
                                                                     # строки датафрейма h, коих n
  h_boot <- h[h_rows_ind, ]                                          # формируем новый датафрейм
                                                                     # из выбранных строк h
  model_boot <- glm(formula = work ~ skills + male +                 # оцениваем модель по      
                              experience + I(experience ^ 2) +       # новой выборке
                              I(skills * male) +
                              weight,                                                 
                              data = h_boot,                                         
                     
                    family = binomial(link = "logit"))                
  gamma_boot <- model_boot$coefficients                              # получаем оценки коэффициентов
  OR_boot[i] <- exp(gamma_boot["experience"] +                       # оцениваем изменение отношений
                    gamma_boot["I(experience^2)"] +                  # шансов вследствие изменения
                    2 * gamma_boot["I(experience^2)"] *              # переменной experience на единицу
                    Boris$experience)              
}
q_L_boot <- quantile(OR_boot, 0.05)                                  # левая граница
q_R_boot <- quantile(OR_boot, 0.95)                                  # правая граница
ci_boot <- c(q_L_boot, q_R_boot)                                     # объединяем результат
print(ci_boot)                                                       # и смотрим на него

# Сравним результаты, полученные с помощью
# дельта метода и бутстрапа
data.frame("Classic" = as.vector(ci),
           "Bootstrap" = ci_boot)

# ЗАДАНИЯ (* - непросто, ** - сложно, *** - брутально)
# 4.1.    Постройте 95% асимптотический доверительный 
#         интервал для отношения шансов
# 4.2.    Постройте 95% асимптотический доверительный интервал
#         для изменения отношений шансов вследствие изменения
#         на единицу переменной skills:
#         1*)    с помощью дельта метода
#         2*)    с помощью бутстрапа
# 4.3**.  Напишите функцию, позволящую, по аналогии с
#         ProbitME, рассчитывать предельные эффекты
#         переменных на отношения шансов

#---------------------------------------------------
# Часть 5. Линейная вероятностная модель
#---------------------------------------------------

# Обратим внимание, что предполагаемый пробит моделью
# процесс генерации данных не согласуется с тем, что
# предполагается линейной вероятностной модель. Однако,
# для простоты будем игнорировать данное обстоятельство.

#*******************************
# Пользовательский уровень
#*******************************

# Получим оценки линейной по вероятностям модели
# при помощи МНК регрессии, реализованной в рамках
# функции lm()
model_ls <- lm(formula = work ~ skills + male + experience +       
                         I(experience ^ 2) +
                         I(skills * male) +
                         weight,                                                 
               data = h)

# Достанем оценки
gamma_est <- model_ls$coefficients

# Посмотрим на оценки вероятностей и убедимся,
# что некоторые из них отрицательны или больше
# единицы
prob_est <- predict(model_ls)                                         # получаем оценки
hist(prob_est)                                                        # строим гистограмму
summary(prob_est)                                                     # смотрим на выборочные
                                                                      # характеристики
sum((prob_est > 1) | (prob_est < 0)) / n                              # доля оценок вероятностей, выпадающих
                                                                      # за интервал от 0 до 1

# Посмотрим на выдачу обычной функции lm(), которая опирается
# на оценку асимптотической ковариационной матрицы оценок
# коэффициентов, не учитывающую специфику предполагаемого
# линейной вероятностной моделью распределения случайных ошибок
summary(model_ls)
# Поскольку используемая оценка асимптотической ковариационной
# матрицы может быть несостоятельна, то интерпретировать
# результаты тестов ориентируясь на полученные из функции
# lm() значения мы не можем

# ЗАДАНИЯ (* - непросто, ** - сложно, *** - брутально)
# 5.1.    Посчитайте предельные эффекты по каждой
#         из переменных на вероятность занятости
# 5.2*.   Оцените дисперсии случайных ошибок и
#         рассчитайте долю отрицательных значенй
#         среди них


#*******************************
# Академический уровень
#*******************************

# Теперь построим 90% бутстрапированный доверительный интервал
# для каждого из коэффициентов
boot_iter <- 100                                                     # число бутстрап итераций
gamma_boot <- matrix(NA,                                             # матрица, в которую будем сохранять
                     nrow = boot_iter,                               # оценки коэффициентов
                     ncol = length(gamma_est))                          
colnames(gamma_boot) <- names(gamma_est)

for(i in 1:boot_iter)                       
{
  h_rows_ind <- sample(1:n, n, TRUE)                                 # случайным образом отбираем
                                                                     # строки датафрейма h, коих n
  h_boot <- h[h_rows_ind, ]                                          # формируем новый датафрейм
                                                                     # из выбранных строк h
  model_boot <- lm(formula = work ~ skills + male +                  # оцениваем модель по      
                             experience + I(experience ^ 2) +        # новой выборке
                             I(skills * male) +
                             weight,                                                 
                   data = h_boot)                
  gamma_boot[i, ] <- model_boot$coefficients                         # получаем оценки коэффициентов
}
# Рассмотрим АДИ для коэффициента при skills
q_L_boot <- quantile(gamma_boot[, "skills"], 0.05)                   # левая граница
q_R_boot <- quantile(gamma_boot[, "skills"], 0.95)                   # правая граница
ci_boot <- c(q_L_boot, q_R_boot)                                     # объединяем результат
print(ci_boot)                                                       # и смотрим на него

# ЗАДАНИЯ (* - непросто, ** - сложно, *** - брутально)
# 5.1.    Постройте 95% бутстрапированный ДИ для коэффициента
#         при переменной experience
# 5.1*.   Постройте 95% бутстрапированный ДИ для
#         вероятности того, что Борис является занятым